# ğŸ¯ HÆ°á»›ng dáº«n sá»­ dá»¥ng LoRA Adapter trong VieNeu-TTS

## ğŸ“– Giá»›i thiá»‡u

Tab "LoRA Adapter" cho phÃ©p báº¡n sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh giá»ng nÃ³i Ä‘Ã£ Ä‘Æ°á»£c fine-tune báº±ng LoRA (Low-Rank Adaptation) tá»« HuggingFace.

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### BÆ°á»›c 1: Táº£i Model cÆ¡ báº£n
1. Chá»n **Backbone** phÃ¹ há»£p (vd: `VieNeu-TTS-0.3B (GPU)`)
2. Chá»n **Codec** (vd: `NeuCodec (Distill)`)
3. **Bá» TICK** "ğŸš€ Optimize with LMDeploy" (LoRA khÃ´ng tÆ°Æ¡ng thÃ­ch vá»›i LMDeploy)
4. Click **ğŸ”„ Táº£i Model**

### BÆ°á»›c 2: Chuyá»ƒn sang tab "ğŸ¯ LoRA Adapter"

### BÆ°á»›c 3: Nháº­p thÃ´ng tin LoRA
- **HuggingFace Repo ID**: Nháº­p repo ID cá»§a LoRA adapter  
  VÃ­ dá»¥: `pnnbao-ump/VieNeu-TTS-0.3B-lora-ngoc-huyen`
  
- **HF Token** (tÃ¹y chá»n): Chá»‰ cáº§n Ä‘iá»n náº¿u repo lÃ  private
  - Láº¥y token táº¡i: https://huggingface.co/settings/tokens
  - Äá»ƒ trá»‘ng náº¿u repo lÃ  public

### BÆ°á»›c 4: Upload Audio Reference
- **Audio reference**: Upload file audio tá»« táº­p train cá»§a LoRA (3-15 giÃ¢y)
- **Text tÆ°Æ¡ng á»©ng**: Nháº­p chÃ­nh xÃ¡c ná»™i dung cá»§a audio (ká»ƒ cáº£ dáº¥u cÃ¢u)

âš ï¸ **LÆ°u Ã½ quan trá»ng:**
- Audio reference **pháº£i** lÃ  má»™t trong cÃ¡c audio Ä‘Ã£ dÃ¹ng Ä‘á»ƒ train LoRA
- Text pháº£i khá»›p **chÃ­nh xÃ¡c 100%** vá»›i ná»™i dung audio (ká»ƒ cáº£ dáº¥u cÃ¢u .,?!)
- LoRA adapter pháº£i tÆ°Æ¡ng thÃ­ch vá»›i backbone Ä‘Ã£ chá»n

### BÆ°á»›c 5: Tá»•ng há»£p giá»ng nÃ³i
1. Nháº­p vÄƒn báº£n cáº§n tá»•ng há»£p
2. Click **ğŸµ Báº¯t Ä‘áº§u**
3. Há»‡ thá»‘ng sáº½:
   - Táº£i base model
   - Táº£i vÃ  merge LoRA adapter
   - Tá»•ng há»£p giá»ng nÃ³i
   - Tá»± Ä‘á»™ng cleanup vÃ  restore model gá»‘c

## ğŸ“ VÃ­ dá»¥

```
Repo ID: pnnbao-ump/VieNeu-TTS-0.3B-lora-ngoc-huyen
HF Token: (Ä‘á»ƒ trá»‘ng náº¿u public)
Audio: ngochuyen_00123.wav (tá»« táº­p train)
Text: "HÃ  Ná»™i mÃ¹a thu Ä‘áº¹p láº¯m."
```

## ğŸ”§ Kháº¯c phá»¥c sá»± cá»‘

### Lá»—i "LoRA khÃ´ng há»— trá»£ LMDeploy"
- Bá» tick "ğŸš€ Optimize with LMDeploy" 
- Reload model
- LoRA sáº½ cháº¡y vá»›i standard PyTorch backend (cháº­m hÆ¡n nhÆ°ng váº«n á»•n)

### Lá»—i "Failed to load LoRA"
- Kiá»ƒm tra Repo ID cÃ³ Ä‘Ãºng khÃ´ng
- Náº¿u repo private, hÃ£y thÃªm HF Token
- Äáº£m báº£o LoRA tÆ°Æ¡ng thÃ­ch vá»›i backbone

### Lá»—i "Out of Memory"
- LoRA cáº§n RAM/VRAM Ä‘á»ƒ merge
- Thá»­ giáº£m batch size
- Sá»­ dá»¥ng backbone nhá» hÆ¡n (0.3B thay vÃ¬ 0.5B)

### Audio cháº¥t lÆ°á»£ng kÃ©m
- Äáº£m báº£o audio reference tá»« táº­p train
- Text reference pháº£i khá»›p chÃ­nh xÃ¡c
- Thá»­ giá»ng reference khÃ¡c tá»« táº­p train

## ğŸ’¡ Tips

1. **Audio reference tá»‘t nháº¥t**: Chá»n audio cÃ³ cháº¥t lÆ°á»£ng cao, rÃµ rÃ ng
2. **Text chÃ­nh xÃ¡c**: Viáº¿t Ä‘Ãºng chÃ­nh táº£, dáº¥u cÃ¢u
3. **TÆ°Æ¡ng thÃ­ch**: Äáº£m báº£o LoRA Ä‘Æ°á»£c train trÃªn cÃ¹ng base model
4. **RAM/VRAM**: LoRA cáº§n thÃªm 1-2GB VRAM khi merge
5. **âš¡ Tá»‘c Ä‘á»™**: Model sáº½ tá»± Ä‘á»™ng giá»¯ LoRA Ä‘Ã£ load trong bá»™ nhá»›. Láº§n nháº¥n nÃºt "Báº¯t Ä‘áº§u" thá»© 2 trá»Ÿ Ä‘i sáº½ khÃ´ng tá»‘n thá»i gian load láº¡i LoRA, giÃºp tá»‘c Ä‘á»™ sinh giá»ng nhanh nhÆ° model gá»‘c. (Trá»« khi báº¡n Ä‘á»•i Repo ID khÃ¡c hoáº·c chuyá»ƒn tab).

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [Fine-tune VieNeu-TTS vá»›i LoRA](../finetune/README.md)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [PEFT Library](https://github.com/huggingface/peft)
